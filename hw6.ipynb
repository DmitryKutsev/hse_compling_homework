{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled23.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMaP1zHrqi/6mOYLohHG6Av",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/hse_compling_homework/blob/master/hw6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEfNUCBFBGjx",
        "colab_type": "code",
        "outputId": "cade3a8b-7b75-4db3-9220-e24e24c1f2f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.1/lenta-ru-news.csv.bz2"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-20 06:09:04--  https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.1/lenta-ru-news.csv.bz2\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/87156914/619f9f00-1e96-11ea-946e-dac89df8aced?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200220%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200220T060904Z&X-Amz-Expires=300&X-Amz-Signature=d2b5e89aea7ecde73da1586c48de9573ad14851b8a50557016506a161534d447&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.bz2&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-02-20 06:09:04--  https://github-production-release-asset-2e65be.s3.amazonaws.com/87156914/619f9f00-1e96-11ea-946e-dac89df8aced?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200220%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200220T060904Z&X-Amz-Expires=300&X-Amz-Signature=d2b5e89aea7ecde73da1586c48de9573ad14851b8a50557016506a161534d447&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.bz2&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.10.139\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.10.139|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 346031300 (330M) [application/octet-stream]\n",
            "Saving to: ‘lenta-ru-news.csv.bz2’\n",
            "\n",
            "lenta-ru-news.csv.b 100%[===================>] 330.00M  41.6MB/s    in 7.0s    \n",
            "\n",
            "2020-02-20 06:09:11 (47.5 MB/s) - ‘lenta-ru-news.csv.bz2’ saved [346031300/346031300]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjFg8bpAssV7",
        "colab_type": "code",
        "outputId": "54e5e035-1fbb-4495-e436-6c4784105b7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!wget https://rusvectores.org/static/models/rusvectores2/news_mystem_skipgram_1000_20_2015.bin.gz\n",
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-20 06:09:15--  https://rusvectores.org/static/models/rusvectores2/news_mystem_skipgram_1000_20_2015.bin.gz\n",
            "Resolving rusvectores.org (rusvectores.org)... 116.203.104.23\n",
            "Connecting to rusvectores.org (rusvectores.org)|116.203.104.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 549952184 (524M) [application/x-gzip]\n",
            "Saving to: ‘news_mystem_skipgram_1000_20_2015.bin.gz’\n",
            "\n",
            "news_mystem_skipgra 100%[===================>] 524.47M  28.6MB/s    in 19s     \n",
            "\n",
            "2020-02-20 06:09:35 (27.6 MB/s) - ‘news_mystem_skipgram_1000_20_2015.bin.gz’ saved [549952184/549952184]\n",
            "\n",
            "lenta-ru-news.csv.bz2  news_mystem_skipgram_1000_20_2015.bin.gz  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WPvPEgeb98S",
        "colab_type": "code",
        "outputId": "6a69d8ff-08e0-482e-c91d-1cb32e48a769",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "#!rm model.bin model.txt \n",
        "# !wget http://vectors.nlpl.eu/repository/20/186.zip\n",
        "!wget http://vectors.nlpl.eu/repository/20/185.zip\n",
        "!unzip 185.zip\n",
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-20 06:09:38--  http://vectors.nlpl.eu/repository/20/185.zip\n",
            "Resolving vectors.nlpl.eu (vectors.nlpl.eu)... 129.240.189.225\n",
            "Connecting to vectors.nlpl.eu (vectors.nlpl.eu)|129.240.189.225|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 639268566 (610M) [application/zip]\n",
            "Saving to: ‘185.zip’\n",
            "\n",
            "185.zip             100%[===================>] 609.65M  23.1MB/s    in 32s     \n",
            "\n",
            "2020-02-20 06:10:10 (19.1 MB/s) - ‘185.zip’ saved [639268566/639268566]\n",
            "\n",
            "Archive:  185.zip\n",
            "  inflating: meta.json               \n",
            "  inflating: model.bin               \n",
            "  inflating: model.txt               \n",
            "  inflating: README                  \n",
            "185.zip\t\t       model.bin\t\t\t\t README\n",
            "lenta-ru-news.csv.bz2  model.txt\t\t\t\t sample_data\n",
            "meta.json\t       news_mystem_skipgram_1000_20_2015.bin.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrGWKppNE97u",
        "colab_type": "code",
        "outputId": "012fdb1b-50c3-40e9-f14f-47a917574fef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "source": [
        "!wget https://github.com/DmitryKutsev/hse_compling_homework/blob/master/paraphraser_gold.zip?raw=true\n",
        "!wget https://github.com/DmitryKutsev/hse_compling_homework/blob/master/data_paraphraser_norm.csv?raw=true\n",
        "!mv paraphraser_gold.zip?raw=true paraphraser_gold.zip\n",
        "!mv data_paraphraser_norm.csv?raw=true data_paraphraser_norm.csv\n",
        "!unzip paraphraser_gold.zip\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-20 06:10:26--  https://github.com/DmitryKutsev/hse_compling_homework/blob/master/paraphraser_gold.zip?raw=true\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/DmitryKutsev/hse_compling_homework/raw/master/paraphraser_gold.zip [following]\n",
            "--2020-02-20 06:10:27--  https://github.com/DmitryKutsev/hse_compling_homework/raw/master/paraphraser_gold.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/DmitryKutsev/hse_compling_homework/master/paraphraser_gold.zip [following]\n",
            "--2020-02-20 06:10:27--  https://raw.githubusercontent.com/DmitryKutsev/hse_compling_homework/master/paraphraser_gold.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 118720 (116K) [application/zip]\n",
            "Saving to: ‘paraphraser_gold.zip?raw=true’\n",
            "\n",
            "\r          paraphras   0%[                    ]       0  --.-KB/s               \rparaphraser_gold.zi 100%[===================>] 115.94K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2020-02-20 06:10:27 (3.08 MB/s) - ‘paraphraser_gold.zip?raw=true’ saved [118720/118720]\n",
            "\n",
            "--2020-02-20 06:10:28--  https://github.com/DmitryKutsev/hse_compling_homework/blob/master/data_paraphraser_norm.csv?raw=true\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/DmitryKutsev/hse_compling_homework/raw/master/data_paraphraser_norm.csv [following]\n",
            "--2020-02-20 06:10:28--  https://github.com/DmitryKutsev/hse_compling_homework/raw/master/data_paraphraser_norm.csv\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/DmitryKutsev/hse_compling_homework/master/data_paraphraser_norm.csv [following]\n",
            "--2020-02-20 06:10:28--  https://raw.githubusercontent.com/DmitryKutsev/hse_compling_homework/master/data_paraphraser_norm.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3575140 (3.4M) [text/plain]\n",
            "Saving to: ‘data_paraphraser_norm.csv?raw=true’\n",
            "\n",
            "data_paraphraser_no 100%[===================>]   3.41M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-02-20 06:10:29 (29.9 MB/s) - ‘data_paraphraser_norm.csv?raw=true’ saved [3575140/3575140]\n",
            "\n",
            "Archive:  paraphraser_gold.zip\n",
            "  inflating: paraphrases_gold.xml    \n",
            "185.zip\t\t\t   news_mystem_skipgram_1000_20_2015.bin.gz\n",
            "data_paraphraser_norm.csv  paraphraser_gold.zip\n",
            "lenta-ru-news.csv.bz2\t   paraphrases_gold.xml\n",
            "meta.json\t\t   README\n",
            "model.bin\t\t   sample_data\n",
            "model.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMeuIrD5if_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!bzip2 -d lenta-ru-news.csv.bz2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWZRDAhDimQk",
        "colab_type": "code",
        "outputId": "9e99e680-1985-4301-aab5-cf40624bfd1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "!ls\n",
        "!pip install pymorphy2[fast]\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "185.zip\t\t\t   news_mystem_skipgram_1000_20_2015.bin.gz\n",
            "data_paraphraser_norm.csv  paraphraser_gold.zip\n",
            "lenta-ru-news.csv\t   paraphrases_gold.xml\n",
            "meta.json\t\t   README\n",
            "model.bin\t\t   sample_data\n",
            "model.txt\n",
            "Collecting pymorphy2[fast]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 1.7MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Collecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting DAWG>=0.7.3; extra == \"fast\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/ef/91b619a399685f7a0a95a03628006ba814d96293bbbbed234ee66fbdefd9/DAWG-0.8.0.tar.gz (371kB)\n",
            "\u001b[K     |████████████████████████████████| 378kB 57.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: DAWG\n",
            "  Building wheel for DAWG (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for DAWG: filename=DAWG-0.8.0-cp36-cp36m-linux_x86_64.whl size=853061 sha256=9ab296acac11c31edd096e791dc378675c3d73d6618e1f47e4436296096fbd0d\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/1f/f0/a5b1f9d02e193c997d252c33d215f24dfd7a448bc0166b2a12\n",
            "Successfully built DAWG\n",
            "Installing collected packages: pymorphy2-dicts, dawg-python, DAWG, pymorphy2\n",
            "Successfully installed DAWG-0.8.0 dawg-python-0.7.2 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zX7M6MAkoQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from collections import Counter,defaultdict\n",
        "from sklearn.decomposition import TruncatedSVD, NMF, PCA\n",
        "from string import punctuation\n",
        "import os\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from lxml import html\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "import gensim\n",
        "import numpy as np\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "morph = MorphAnalyzer()\n",
        "punct = punctuation+'«»—…“”*№–,'\n",
        "stops = set(stopwords.words('russian'))\n",
        "\n",
        "def normalize(text):\n",
        "    \n",
        "    words = [word.strip(punct) for word in text.lower().split()]\n",
        "    words = [morph.parse(word)[0].normal_form for word in words if word and word not in stops]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "def tokenize(text):\n",
        "    \n",
        "    words = [word.strip(punct) for word in text.lower().split()]\n",
        "\n",
        "    return ' '.join(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHRVBKC9niKF",
        "colab_type": "code",
        "outputId": "4dffd576-7842-4bd7-cfca-ef91a605bf41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_handler = open('lenta-ru-news.csv', 'r')\n",
        "data = data_handler.read()\n",
        "print(len(data))\n",
        "data = data[:6000000]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1172327461\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWmUFssTRnoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_norm = [normalize(text) for text in data.split('.')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J3zqnP8Rnmh",
        "colab_type": "code",
        "outputId": "d029dd6d-cf24-487b-a6d4-d3b690eee5a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "data_norm = [text for text in data_norm if text]\n",
        "print(len(data_norm))\n",
        "data_norm[:6]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['url,title,text,topic,tags,date https://lenta',\n",
              " 'ru/news/1914/09/16/hungarnn/,1914',\n",
              " 'русский войско вступить предел венгрия бой сопоцкина друскеник закончиться отступление германец',\n",
              " 'неприятель приблизиться север осовца начать артиллерийский борьба крепость',\n",
              " 'артиллерийский бой принимать участие тяжёлый калибр',\n",
              " 'ранний утро 14 сентябрь огонь достигнуть значительный напряжение']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqanL3ybRnjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_w2v = gensim.models.Word2Vec([text.split() for text in data_norm], size=50, sg=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNTHoPBj4OD3",
        "colab_type": "code",
        "outputId": "adcab8d8-2512-48a4-f1df-b4638832b94f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "my_w2v.most_similar('чечня')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('дагестан', 0.8110010623931885),\n",
              " ('чеченский', 0.8019987940788269),\n",
              " ('республика', 0.772249162197113),\n",
              " ('гудермес', 0.7575880289077759),\n",
              " ('грозный', 0.7467355728149414),\n",
              " ('контртеррористический', 0.7358383536338806),\n",
              " ('чеченец', 0.7267937064170837),\n",
              " ('ботлихский', 0.7262543439865112),\n",
              " ('аслан', 0.7258008718490601),\n",
              " ('грузия', 0.7255139946937561)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UjOP9Mq4b54",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dim = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nepsHLlxfyW7",
        "colab_type": "code",
        "outputId": "54fa298a-ec16-4f97-dee0-14799bf9c376",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "rusv_v2w = gensim.models.KeyedVectors.load_word2vec_format('model.bin', binary=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K80JkCtYfy0H",
        "colab_type": "code",
        "outputId": "a89a31ac-4831-4256-ec2c-b0f06e39fed1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "rusv_v2w.most_similar('путин_NOUN')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('путина_NOUN', 0.7462903261184692),\n",
              " ('россия_NOUN', 0.725328266620636),\n",
              " ('медведев_NOUN', 0.6876657605171204),\n",
              " ('зюган_NOUN', 0.6616120338439941),\n",
              " ('жириновский_ADJ', 0.6568332314491272),\n",
              " ('путин_PROPN', 0.6374367475509644),\n",
              " ('лдпр_NOUN', 0.6191665530204773),\n",
              " ('жирик_NOUN', 0.6120600700378418),\n",
              " ('кпрфа_PROPN', 0.6116076707839966),\n",
              " ('россие_NOUN', 0.6096259355545044)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-7ficwpVPDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_df_embedding(text, model, dim):\n",
        "    text = text.split()\n",
        "    words = Counter(text)\n",
        "    total = len(text)\n",
        "    vectors = np.zeros((len(words), dim))   \n",
        "    for i, word in enumerate(words):\n",
        "        try:\n",
        "            v = model[word]\n",
        "        except (KeyError, ValueError) as errs:\n",
        "            #print(errs)\n",
        "            continue\n",
        "        vectors[i] = v*(words[word]/total)\n",
        "\n",
        "    if vectors.any():\n",
        "        vector = np.average(vectors, axis=0)\n",
        "    else:\n",
        "        vector = np.zeros((dim))\n",
        "    \n",
        "    return vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwMRV4iJXrxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_xml = html.fromstring(open('paraphrases_gold.xml', 'rb').read())\n",
        "texts_1 = []\n",
        "texts_2 = []\n",
        "classes = []\n",
        "\n",
        "for p in corpus_xml.xpath('//paraphrase'):\n",
        "    texts_1.append(p.xpath('./value[@name=\"text_1\"]/text()')[0])\n",
        "    texts_2.append(p.xpath('./value[@name=\"text_2\"]/text()')[0])\n",
        "    classes.append(p.xpath('./value[@name=\"class\"]/text()')[0])\n",
        "    \n",
        "df_data = pd.DataFrame({'text_1':texts_1, 'text_2':texts_2, 'label':classes})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xemqbs8R6R0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data['text_1_norm'] = df_data['text_1'].apply(normalize)\n",
        "df_data['text_2_norm'] = df_data['text_2'].apply(normalize)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foeHzuCyYbeN",
        "colab_type": "code",
        "outputId": "b43141f6-6527-4457-c54f-5465f333139a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "dim = 50\n",
        "df_data['text_1_notnorm'] = df_data['text_1'].apply(tokenize)\n",
        "df_data['text_2_notnorm'] = df_data['text_2'].apply(tokenize)\n",
        "\n",
        "X_text_1_ft = np.zeros((len(df_data['text_1_notnorm']), dim))\n",
        "X_text_2_ft = np.zeros((len(df_data['text_2_notnorm']), dim))\n",
        "\n",
        "for i, text in enumerate(df_data['text_1_notnorm'].values):\n",
        "    X_text_1_ft[i] = get_df_embedding(text, my_w2v, dim)\n",
        "    \n",
        "for i, text in enumerate(df_data['text_2_notnorm'].values):\n",
        "    X_text_2_ft[i] = get_df_embedding(text, my_w2v, dim)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rb8a07_TK9B",
        "colab_type": "code",
        "outputId": "0201f183-8d8a-42ae-cef8-87d888974009",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "df_data.head(5)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_1</th>\n",
              "      <th>text_2</th>\n",
              "      <th>label</th>\n",
              "      <th>text_1_norm</th>\n",
              "      <th>text_2_norm</th>\n",
              "      <th>text_1_notnorm</th>\n",
              "      <th>text_2_notnorm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Цены на нефть восстанавливаются</td>\n",
              "      <td>Парламент Словакии поблагодарил народы бывшего...</td>\n",
              "      <td>-1</td>\n",
              "      <td>цена нефть восстанавливаться</td>\n",
              "      <td>парламент словакия поблагодарить народ бывший ...</td>\n",
              "      <td>цены на нефть восстанавливаются</td>\n",
              "      <td>парламент словакии поблагодарил народы бывшего...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"Гоголь-центр\" покажет видеозапись скандальног...</td>\n",
              "      <td>Кехман запретил «Гоголь-центру» показывать вид...</td>\n",
              "      <td>-1</td>\n",
              "      <td>гоголь-центр показать видеозапись скандальный ...</td>\n",
              "      <td>кехман запретить гоголь-центр показывать видео...</td>\n",
              "      <td>гоголь-центр покажет видеозапись скандального ...</td>\n",
              "      <td>кехман запретил гоголь-центру показывать видео...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Агент: РФС вновь задерживает зарплату Фабио Ка...</td>\n",
              "      <td>СМИ: Агент Фабио Капелло грозится подать в суд...</td>\n",
              "      <td>-1</td>\n",
              "      <td>агент рфс вновь задерживать зарплата фабио кап...</td>\n",
              "      <td>сми агент фабио капелло грозиться подать суд рфс</td>\n",
              "      <td>агент рфс вновь задерживает зарплату фабио кап...</td>\n",
              "      <td>сми агент фабио капелло грозится подать в суд ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>День Победы в Москве обещает выдаться облачным</td>\n",
              "      <td>Любляна отпразднует День Победы вместе с Москвой</td>\n",
              "      <td>-1</td>\n",
              "      <td>день победа москва обещать выдаться облачный</td>\n",
              "      <td>люблян отпраздновать день победа вместе москва</td>\n",
              "      <td>день победы в москве обещает выдаться облачным</td>\n",
              "      <td>любляна отпразднует день победы вместе с москвой</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Посол РФ в США: Россия будет бороться с попытк...</td>\n",
              "      <td>Правительство запланировало заработать на лоте...</td>\n",
              "      <td>-1</td>\n",
              "      <td>посол рф сша россия бороться попытка переписат...</td>\n",
              "      <td>правительство запланировать заработать лотерея...</td>\n",
              "      <td>посол рф в сша россия будет бороться с попытка...</td>\n",
              "      <td>правительство запланировало заработать на лоте...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              text_1  ...                                     text_2_notnorm\n",
              "0                    Цены на нефть восстанавливаются  ...  парламент словакии поблагодарил народы бывшего...\n",
              "1  \"Гоголь-центр\" покажет видеозапись скандальног...  ...  кехман запретил гоголь-центру показывать видео...\n",
              "2  Агент: РФС вновь задерживает зарплату Фабио Ка...  ...  сми агент фабио капелло грозится подать в суд ...\n",
              "3     День Победы в Москве обещает выдаться облачным  ...   любляна отпразднует день победы вместе с москвой\n",
              "4  Посол РФ в США: Россия будет бороться с попытк...  ...  правительство запланировало заработать на лоте...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf1GHgTxi4_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_text_ft = np.concatenate([X_text_1_ft, X_text_2_ft], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ar1wE4jjJT6",
        "colab_type": "code",
        "outputId": "a0abfcce-6f70-40df-bd49-24f07fce5427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#Обученная модель w2v\n",
        "y = df_data['label'].values\n",
        "train_X, valid_X, train_y, valid_y = train_test_split(X_text_ft, y,random_state=1)\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=7, min_samples_leaf=15,\n",
        "                             class_weight='balanced')\n",
        "clf.fit(train_X, train_y)\n",
        "preds = clf.predict(valid_X)\n",
        "print(classification_report(valid_y, preds))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.51      0.57      0.54       181\n",
            "           0       0.55      0.49      0.52       207\n",
            "           1       0.24      0.26      0.25        93\n",
            "\n",
            "    accuracy                           0.47       481\n",
            "   macro avg       0.44      0.44      0.44       481\n",
            "weighted avg       0.48      0.47      0.47       481\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2zSaWSFv_TU",
        "colab_type": "code",
        "outputId": "973c9aca-cebf-4e44-a7b9-34779f7899ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(clf, X_text_ft, y, cv=5, scoring = 'f1_micro')\n",
        "scores.mean()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.41530573593073594"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXr_4FbN2fDQ",
        "colab_type": "code",
        "outputId": "ac71802f-f726-4f1e-cd80-1b8d2f235aa2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "train_X, valid_X, train_y, valid_y = train_test_split(X_text_ft, y,random_state=1)\n",
        "clf = LogisticRegression(C=1000)\n",
        "clf.fit(train_X, train_y)\n",
        "preds = clf.predict(valid_X)\n",
        "print(classification_report(valid_y, preds))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.51      0.47       181\n",
            "           0       0.47      0.57      0.52       207\n",
            "           1       0.16      0.03      0.05        93\n",
            "\n",
            "    accuracy                           0.44       481\n",
            "   macro avg       0.35      0.37      0.35       481\n",
            "weighted avg       0.40      0.44      0.41       481\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgqVsdwZr1Kf",
        "colab_type": "code",
        "outputId": "fc3fbaad-be55-4b98-dac5-fd3bab344de1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "scores = cross_val_score(clf, X_text_ft, y, cv=5, scoring = 'f1_micro')\n",
        "scores.mean()"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.436827329418465"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1SnTUYfNlcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_csv = pd.read_csv('data_paraphraser_norm.csv', error_bad_lines=False)\n",
        "#модель с русвекторес w2v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my1_c2cNtWDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "dim = 50\n",
        "\n",
        "X_text_1_ft = np.zeros((len(corpus_csv['text_1_norm']), 300))\n",
        "X_text_2_ft = np.zeros((len(corpus_csv['text_2_norm']), 300))\n",
        "\n",
        "for i, text in enumerate(corpus_csv['text_1_norm'].values):\n",
        "    X_text_1_ft[i] = get_df_embedding(text, rusv_v2w, 300)\n",
        "    \n",
        "for i, text in enumerate(corpus_csv['text_2_norm'].values):\n",
        "    X_text_2_ft[i] = get_df_embedding(text, rusv_v2w, 300)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL4XpW1UNIsB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_text_ft = np.concatenate([X_text_1_ft, X_text_2_ft], axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPQvZdG0NIuY",
        "colab_type": "code",
        "outputId": "80783ba0-005c-4e6d-c1ce-0b73390aad48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "y = corpus_csv['label'].values\n",
        "train_X, valid_X, train_y, valid_y = train_test_split(X_text_ft, y,random_state=1)\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=7, min_samples_leaf=15,\n",
        "                             class_weight='balanced')\n",
        "clf.fit(train_X, train_y)\n",
        "preds = clf.predict(valid_X)\n",
        "print(classification_report(valid_y, preds))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.53      0.58      0.56       629\n",
            "           0       0.49      0.50      0.50       737\n",
            "           1       0.36      0.30      0.33       441\n",
            "\n",
            "    accuracy                           0.48      1807\n",
            "   macro avg       0.46      0.46      0.46      1807\n",
            "weighted avg       0.47      0.48      0.48      1807\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s52-nFsouZSY",
        "colab_type": "code",
        "outputId": "a92f767f-aab2-4c26-9285-36d9cefb61bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "scores = cross_val_score(clf, X_text_ft, y, cv=5, scoring = 'f1_micro')\n",
        "scores.mean()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4383491507415756"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd1sn0sFiU2S",
        "colab_type": "code",
        "outputId": "94db5d24-89e5-42b6-cb4c-4713e6543468",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "y = corpus_csv['label'].values\n",
        "train_X, valid_X, train_y, valid_y = train_test_split(X_text_ft, y,random_state=1)\n",
        "clf = RandomForestClassifier(n_estimators=200, max_depth=7, min_samples_leaf=15,\n",
        "                             class_weight='balanced')\n",
        "clf.fit(train_X, train_y)\n",
        "preds = clf.predict(valid_X)\n",
        "print(classification_report(valid_y, preds))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.56      0.58      0.57       629\n",
            "           0       0.48      0.53      0.50       737\n",
            "           1       0.39      0.31      0.34       441\n",
            "\n",
            "    accuracy                           0.49      1807\n",
            "   macro avg       0.48      0.47      0.47      1807\n",
            "weighted avg       0.49      0.49      0.49      1807\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxNJd005SPmX",
        "colab_type": "code",
        "outputId": "e8dacfd3-0cfd-4f3e-e88e-fa677bff49b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(clf, X_text_ft, y, cv=5, scoring = 'f1_micro')\n",
        "scores.mean()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.44415904511670423"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuM2A85CuRPW",
        "colab_type": "code",
        "outputId": "c7d35097-08e2-41d1-ae57-3beeede15966",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "vectors_df = corpus_csv\n",
        "\n",
        "vectors_df['text_1_nor'] = vectors_df['text_1'].apply(normalize)\n",
        "vectors_df['text_2_nor'] = vectors_df['text_2'].apply(normalize)\n",
        "vectors_df.head(2)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text_1</th>\n",
              "      <th>text_2</th>\n",
              "      <th>text_1_norm</th>\n",
              "      <th>text_2_norm</th>\n",
              "      <th>text_1_nor</th>\n",
              "      <th>text_2_nor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Полицейским разрешат стрелять на поражение по ...</td>\n",
              "      <td>Полиции могут разрешить стрелять по хулиганам ...</td>\n",
              "      <td>полицейский_NOUN разрешать_VERB стрелять_VERB ...</td>\n",
              "      <td>полиция_NOUN мочь_VERB разрешать_VERB стрелять...</td>\n",
              "      <td>полицейский разрешить стрелять поражение гражд...</td>\n",
              "      <td>полиция мочь разрешить стрелять хулиган травма...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Право полицейских на проникновение в жилище ре...</td>\n",
              "      <td>Правила внесудебного проникновения полицейских...</td>\n",
              "      <td>право_ADV полицейский_NOUN на_ADP проникновени...</td>\n",
              "      <td>правило_NOUN внесудебный_ADJ проникновение_NOU...</td>\n",
              "      <td>право полицейский проникновение жилища решить ...</td>\n",
              "      <td>правило внесудебный проникновение полицейский ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  ...                                         text_2_nor\n",
              "0      0  ...  полиция мочь разрешить стрелять хулиган травма...\n",
              "1      0  ...  правило внесудебный проникновение полицейский ...\n",
              "\n",
              "[2 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pD5s6MsLx_Ho",
        "colab": {}
      },
      "source": [
        "data_lines_norm = [normalize(text) for text in data.splitlines()]\n",
        "# тексты для обучения w2v и fasttext"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMtAzgWqzttY",
        "colab_type": "code",
        "outputId": "54ce921c-26c8-4c6b-c669-e01876270c3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "tfidf = TfidfVectorizer(min_df=3, max_df=0.4, max_features=1000)\n",
        "tfidf.fit(pd.concat([vectors_df['text_1_nor'], vectors_df['text_2_nor']]))"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=0.4, max_features=1000,\n",
              "                min_df=3, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
              "                sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVitMIL-obdG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Подсчет косинусного расстояния для SVD и NMF\n",
        "svd = TruncatedSVD(200)\n",
        "\n",
        "X_text_1 = svd.fit_transform(tfidf.transform(vectors_df['text_1_nor']))\n",
        "X_text_2 = svd.fit_transform(tfidf.transform(vectors_df['text_2_nor']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twk5qgdPpInF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vect_dict = []\n",
        "len(distance)\n",
        "distance = np.zeros((len(vectors_df['text_1_nor'].values), dim))\n",
        "for i, text in enumerate(X_text_1):   \n",
        "    distance[i] = cosine_distances(X_text_2[[i]], X_text_1[[i]])[0][0]\n",
        "    vect_dict.append(distance[i][0])\n",
        "vectors_df['distance_svd'] = vect_dict\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDhAxRG1OlYl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nmf = NMF(50)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9WN8D6lOlVh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_text_1_nmf = nmf.fit_transform(tfidf.transform(vectors_df['text_1_nor'].values))\n",
        "X_text_2_nmf = nmf.fit_transform(tfidf.transform(vectors_df['text_2_nor'].values))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5dmmmsfOlSM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vect_dict = []\n",
        "distance = np.zeros((len(vectors_df['text_1_nor'].values), dim))\n",
        "for i, text in enumerate(X_text_1):   \n",
        "    distance[i] = cosine_distances(X_text_2_nmf[[i]], X_text_1_nmf[[i]])[0][0]\n",
        "    vect_dict.append(distance[i][0])\n",
        "vectors_df['distance_nmf'] = vect_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKqt7BInQzZj",
        "colab_type": "code",
        "outputId": "e7a168c2-6b0a-4b2b-b67c-05163a6f6253",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "vectors_df.head(2)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text_1</th>\n",
              "      <th>text_2</th>\n",
              "      <th>text_1_norm</th>\n",
              "      <th>text_2_norm</th>\n",
              "      <th>text_1_nor</th>\n",
              "      <th>text_2_nor</th>\n",
              "      <th>distance_svd</th>\n",
              "      <th>distance_nmf</th>\n",
              "      <th>distance_Word2Vec(vocab=10162, size=50, alpha=0.025)</th>\n",
              "      <th>distance_FastText(vocab=9811, size=50, alpha=0.025)</th>\n",
              "      <th>distance_&lt;gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7f42708f5588&gt;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Полицейским разрешат стрелять на поражение по ...</td>\n",
              "      <td>Полиции могут разрешить стрелять по хулиганам ...</td>\n",
              "      <td>полицейский_NOUN разрешать_VERB стрелять_VERB ...</td>\n",
              "      <td>полиция_NOUN мочь_VERB разрешать_VERB стрелять...</td>\n",
              "      <td>полицейский разрешить стрелять поражение гражд...</td>\n",
              "      <td>полиция мочь разрешить стрелять хулиган травма...</td>\n",
              "      <td>0.945776</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.071811</td>\n",
              "      <td>0.049486</td>\n",
              "      <td>0.129631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Право полицейских на проникновение в жилище ре...</td>\n",
              "      <td>Правила внесудебного проникновения полицейских...</td>\n",
              "      <td>право_ADV полицейский_NOUN на_ADP проникновени...</td>\n",
              "      <td>правило_NOUN внесудебный_ADJ проникновение_NOU...</td>\n",
              "      <td>право полицейский проникновение жилища решить ...</td>\n",
              "      <td>правило внесудебный проникновение полицейский ...</td>\n",
              "      <td>0.965386</td>\n",
              "      <td>0.999481</td>\n",
              "      <td>0.081788</td>\n",
              "      <td>0.057309</td>\n",
              "      <td>0.258133</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  ... distance_<gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7f42708f5588>\n",
              "0      0  ...                                           0.129631                                 \n",
              "1      0  ...                                           0.258133                                 \n",
              "\n",
              "[2 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHqd1GjopIhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fast_text = gensim.models.FastText([text.split() for text in data_lines_norm], size=50, \n",
        "                                   min_n=4, max_n=8) \n",
        "w2v = gensim.models.Word2Vec([text.split() for text in data_lines_norm], size=50, sg=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piKXPD_D_y6x",
        "colab_type": "code",
        "outputId": "d8aedee4-48e5-48cc-9c8e-6b5f951dbc88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Функция, возвращающая косинсное расстояние для оставшихся моделей\n",
        "# на вход подуются тексты 1 и 2 из таблички с перефразами,\n",
        "# модель, и датафрейм, куда пойдет результат\n",
        "\n",
        "def cosine_sim(model, text_1, text_2, res_df, dim=50):\n",
        "\n",
        "  X_text_1 = np.zeros((len(text_1), dim))\n",
        "  X_text_2 = np.zeros((len(text_2), dim))\n",
        "  vect_dict = []\n",
        "  distance = np.zeros((len(vectors_df['text_1_nor'].values), dim))\n",
        "  for i, text in enumerate(text_1.values):\n",
        "      X_text_1[i] = get_df_embedding(text, model, dim)\n",
        "      \n",
        "  for i, text in enumerate(text_2.values):\n",
        "      X_text_2[i] = get_df_embedding(text, model, dim)\n",
        "  for i, text in enumerate(X_text_1):\n",
        "      distance[i] = cosine_distances(X_text_2[[i]], X_text_1[[i]])[0][0]\n",
        "      try:\n",
        "        #print(distance)\n",
        "        vect_dict.append(distance[i][0])\n",
        "      except Exception as e:\n",
        "        pass\n",
        "  res_df['distance_' + str(model)] = vect_dict\n",
        "\n",
        "\n",
        "cosine_sim(my_w2v, vectors_df['text_1_nor'], vectors_df['text_2_nor'], vectors_df, dim=50)\n"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0-ppnxiGTfJ",
        "colab_type": "code",
        "outputId": "21950505-bf33-411b-ca7d-68e8b90ff4f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "cosine_sim(fast_text, vectors_df['text_1_nor'], vectors_df['text_2_nor'], vectors_df, dim=50)"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OutEfmKAIlgS",
        "colab_type": "code",
        "outputId": "2d6d3c54-f16b-428b-b5ae-b661b43439c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "cosine_sim(fast_text, vectors_df['text_1_nor'], vectors_df['text_2_nor'], vectors_df, dim=50)"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1ixJUAwIlcz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cosine_sim(rusv_v2w, vectors_df['text_1_norm'], vectors_df['text_2_norm'], vectors_df, dim=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V52eLskhieIB",
        "colab_type": "code",
        "outputId": "0f1b64c1-7d0f-4595-8801-e15535d8ba53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "source": [
        "vectors_df.head(3)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text_1</th>\n",
              "      <th>text_2</th>\n",
              "      <th>text_1_norm</th>\n",
              "      <th>text_2_norm</th>\n",
              "      <th>text_1_nor</th>\n",
              "      <th>text_2_nor</th>\n",
              "      <th>distance_svd</th>\n",
              "      <th>distance_nmf</th>\n",
              "      <th>distance_Word2Vec(vocab=10162, size=50, alpha=0.025)</th>\n",
              "      <th>distance_FastText(vocab=9811, size=50, alpha=0.025)</th>\n",
              "      <th>distance_&lt;gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7f42708f5588&gt;</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Полицейским разрешат стрелять на поражение по ...</td>\n",
              "      <td>Полиции могут разрешить стрелять по хулиганам ...</td>\n",
              "      <td>полицейский_NOUN разрешать_VERB стрелять_VERB ...</td>\n",
              "      <td>полиция_NOUN мочь_VERB разрешать_VERB стрелять...</td>\n",
              "      <td>полицейский разрешить стрелять поражение гражд...</td>\n",
              "      <td>полиция мочь разрешить стрелять хулиган травма...</td>\n",
              "      <td>0.945776</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.071811</td>\n",
              "      <td>0.060615</td>\n",
              "      <td>0.129631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Право полицейских на проникновение в жилище ре...</td>\n",
              "      <td>Правила внесудебного проникновения полицейских...</td>\n",
              "      <td>право_ADV полицейский_NOUN на_ADP проникновени...</td>\n",
              "      <td>правило_NOUN внесудебный_ADJ проникновение_NOU...</td>\n",
              "      <td>право полицейский проникновение жилища решить ...</td>\n",
              "      <td>правило внесудебный проникновение полицейский ...</td>\n",
              "      <td>0.965386</td>\n",
              "      <td>0.999481</td>\n",
              "      <td>0.081788</td>\n",
              "      <td>0.051587</td>\n",
              "      <td>0.258133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Президент Египта ввел чрезвычайное положение в...</td>\n",
              "      <td>Власти Египта угрожают ввести в стране чрезвыч...</td>\n",
              "      <td>президент_NOUN египет_NOUN вводить_VERB чрезвы...</td>\n",
              "      <td>власть_NOUN египет_NOUN угрожать_VERB вводить_...</td>\n",
              "      <td>президент египет ввести чрезвычайный положение...</td>\n",
              "      <td>власть египет угрожать ввести страна чрезвычай...</td>\n",
              "      <td>1.087920</td>\n",
              "      <td>0.968598</td>\n",
              "      <td>0.092417</td>\n",
              "      <td>0.180118</td>\n",
              "      <td>0.113830</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  ... distance_<gensim.models.keyedvectors.Word2VecKeyedVectors object at 0x7f42708f5588>\n",
              "0      0  ...                                           0.129631                                 \n",
              "1      0  ...                                           0.258133                                 \n",
              "2      0  ...                                           0.113830                                 \n",
              "\n",
              "[3 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxw0epZ6HbKf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#удобный датафрейм\n",
        "vectors_only = vectors_df.drop(['text_1','text_2', 'text_1_norm', 'text_2_norm', 'text_1_nor', 'text_2_nor'], axis=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EshTvYl1AeJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#переименование столбцов\n",
        "vectors_only.columns = ['label','my_w2v', 'fasttext', 'rusv_w2v', 'svd', 'nmf']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1qnthQiokXJ",
        "colab_type": "code",
        "outputId": "67e37b84-0d64-453f-acf7-b70d0674f36d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "vectors_only.head(3)"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>my_w2v</th>\n",
              "      <th>fasttext</th>\n",
              "      <th>rusv_w2v</th>\n",
              "      <th>svd</th>\n",
              "      <th>nmf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.945776</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.071811</td>\n",
              "      <td>0.060615</td>\n",
              "      <td>0.129631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.965386</td>\n",
              "      <td>0.999481</td>\n",
              "      <td>0.081788</td>\n",
              "      <td>0.051587</td>\n",
              "      <td>0.258133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1.087920</td>\n",
              "      <td>0.968598</td>\n",
              "      <td>0.092417</td>\n",
              "      <td>0.180118</td>\n",
              "      <td>0.113830</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label    my_w2v  fasttext  rusv_w2v       svd       nmf\n",
              "0      0  0.945776  1.000000  0.071811  0.060615  0.129631\n",
              "1      0  0.965386  0.999481  0.081788  0.051587  0.258133\n",
              "2      0  1.087920  0.968598  0.092417  0.180118  0.113830"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLkjjK5zVqEa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = vectors_only['label'].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLjPKelAeH9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "predict_list = []\n",
        "for i, lbl in enumerate(y):\n",
        "\n",
        "  pred_i = [vectors_only['nmf'][i], vectors_only['my_w2v'][i], vectors_only['fasttext'][i], vectors_only['rusv_w2v'][i], vectors_only['svd'][i]]\n",
        "  predict_list.append(pred_i)\n",
        "\n",
        "X = predict_list\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aocywywCfAaJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3455bd99-ebc5-40fa-dd01-5086b3f98731"
      },
      "source": [
        "#классификатор и кросс-валидация\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=7, min_samples_leaf=15,\n",
        "                             class_weight='balanced')\n",
        "scores = cross_val_score(clf, X, y, cv=5, scoring = 'f1_micro')\n",
        "scores.mean()"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5370078536662407"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyS2Y1WZ54p3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}