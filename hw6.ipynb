{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled23.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMa/7ej61eLTXlAZCO9dN9M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/hse_compling_homework/blob/master/hw6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEfNUCBFBGjx",
        "colab_type": "code",
        "outputId": "4df4f04d-5628-45c3-cef5-9481fed73383",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "!wget https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.1/lenta-ru-news.csv.bz2"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-19 11:28:58--  https://github.com/yutkin/Lenta.Ru-News-Dataset/releases/download/v1.1/lenta-ru-news.csv.bz2\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/87156914/619f9f00-1e96-11ea-946e-dac89df8aced?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200219%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200219T112858Z&X-Amz-Expires=300&X-Amz-Signature=d8ab225c5ca421e46f10b61090c5b2536a4038d4c4ee2e5338a7abb91aa009f4&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.bz2&response-content-type=application%2Foctet-stream [following]\n",
            "--2020-02-19 11:28:58--  https://github-production-release-asset-2e65be.s3.amazonaws.com/87156914/619f9f00-1e96-11ea-946e-dac89df8aced?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200219%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200219T112858Z&X-Amz-Expires=300&X-Amz-Signature=d8ab225c5ca421e46f10b61090c5b2536a4038d4c4ee2e5338a7abb91aa009f4&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dlenta-ru-news.csv.bz2&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.217.33.4\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.217.33.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 346031300 (330M) [application/octet-stream]\n",
            "Saving to: ‘lenta-ru-news.csv.bz2’\n",
            "\n",
            "lenta-ru-news.csv.b 100%[===================>] 330.00M  48.8MB/s    in 6.8s    \n",
            "\n",
            "2020-02-19 11:29:05 (48.5 MB/s) - ‘lenta-ru-news.csv.bz2’ saved [346031300/346031300]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjFg8bpAssV7",
        "colab_type": "code",
        "outputId": "58c567eb-7b35-4f60-9c64-aa711090553e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "!wget https://rusvectores.org/static/models/rusvectores2/news_mystem_skipgram_1000_20_2015.bin.gz\n",
        "!ls"
      ],
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-19 11:29:07--  https://rusvectores.org/static/models/rusvectores2/news_mystem_skipgram_1000_20_2015.bin.gz\n",
            "Resolving rusvectores.org (rusvectores.org)... 116.203.104.23\n",
            "Connecting to rusvectores.org (rusvectores.org)|116.203.104.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 549952184 (524M) [application/x-gzip]\n",
            "Saving to: ‘news_mystem_skipgram_1000_20_2015.bin.gz.1’\n",
            "\n",
            "news_mystem_skipgra 100%[===================>] 524.47M  24.8MB/s    in 22s     \n",
            "\n",
            "2020-02-19 11:29:29 (24.1 MB/s) - ‘news_mystem_skipgram_1000_20_2015.bin.gz.1’ saved [549952184/549952184]\n",
            "\n",
            "185.zip\t\t\t   model.txt\n",
            "186.zip\t\t\t   news_mystem_skipgram_1000_20_2015.bin.gz\n",
            "data_paraphraser_norm.csv  news_mystem_skipgram_1000_20_2015.bin.gz.1\n",
            "lenta-ru-news.csv\t   paraphraser_gold.zip\n",
            "lenta-ru-news.csv.bz2\t   paraphrases_gold.xml\n",
            "meta.json\t\t   README\n",
            "model.bin\t\t   sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrGWKppNE97u",
        "colab_type": "code",
        "outputId": "5ca1ee79-1c85-4a5f-8b7c-6e8156829dd9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget https://github.com/DmitryKutsev/hse_compling_homework/blob/master/paraphraser_gold.zip?raw=true\n",
        "!wget https://github.com/DmitryKutsev/hse_compling_homework/blob/master/data_paraphraser_norm.csv?raw=true\n",
        "!mv paraphraser_gold.zip?raw=true paraphraser_gold.zip\n",
        "!mv data_paraphraser_norm.csv?raw=true data_paraphraser_norm.csv\n",
        "!unzip paraphraser_gold.zip\n",
        "!ls"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-19 11:29:32--  https://github.com/DmitryKutsev/hse_compling_homework/blob/master/paraphraser_gold.zip?raw=true\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/DmitryKutsev/hse_compling_homework/raw/master/paraphraser_gold.zip [following]\n",
            "--2020-02-19 11:29:32--  https://github.com/DmitryKutsev/hse_compling_homework/raw/master/paraphraser_gold.zip\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/DmitryKutsev/hse_compling_homework/master/paraphraser_gold.zip [following]\n",
            "--2020-02-19 11:29:32--  https://raw.githubusercontent.com/DmitryKutsev/hse_compling_homework/master/paraphraser_gold.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 118720 (116K) [application/zip]\n",
            "Saving to: ‘paraphraser_gold.zip?raw=true’\n",
            "\n",
            "paraphraser_gold.zi 100%[===================>] 115.94K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2020-02-19 11:29:32 (3.68 MB/s) - ‘paraphraser_gold.zip?raw=true’ saved [118720/118720]\n",
            "\n",
            "--2020-02-19 11:29:33--  https://github.com/DmitryKutsev/hse_compling_homework/blob/master/data_paraphraser_norm.csv?raw=true\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github.com/DmitryKutsev/hse_compling_homework/raw/master/data_paraphraser_norm.csv [following]\n",
            "--2020-02-19 11:29:34--  https://github.com/DmitryKutsev/hse_compling_homework/raw/master/data_paraphraser_norm.csv\n",
            "Reusing existing connection to github.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/DmitryKutsev/hse_compling_homework/master/data_paraphraser_norm.csv [following]\n",
            "--2020-02-19 11:29:34--  https://raw.githubusercontent.com/DmitryKutsev/hse_compling_homework/master/data_paraphraser_norm.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3575140 (3.4M) [text/plain]\n",
            "Saving to: ‘data_paraphraser_norm.csv?raw=true’\n",
            "\n",
            "data_paraphraser_no 100%[===================>]   3.41M  20.4MB/s    in 0.2s    \n",
            "\n",
            "2020-02-19 11:29:35 (20.4 MB/s) - ‘data_paraphraser_norm.csv?raw=true’ saved [3575140/3575140]\n",
            "\n",
            "Archive:  paraphraser_gold.zip\n",
            "replace paraphrases_gold.xml? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace paraphrases_gold.xml? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace paraphrases_gold.xml? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace paraphrases_gold.xml? [y]es, [n]o, [A]ll, [N]one, [r]ename: a\n",
            "error:  invalid response [a]\n",
            "replace paraphrases_gold.xml? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: paraphrases_gold.xml    \n",
            "185.zip\t\t\t   model.txt\n",
            "186.zip\t\t\t   news_mystem_skipgram_1000_20_2015.bin.gz\n",
            "data_paraphraser_norm.csv  news_mystem_skipgram_1000_20_2015.bin.gz.1\n",
            "lenta-ru-news.csv\t   paraphraser_gold.zip\n",
            "lenta-ru-news.csv.bz2\t   paraphrases_gold.xml\n",
            "meta.json\t\t   README\n",
            "model.bin\t\t   sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMeuIrD5if_O",
        "colab_type": "code",
        "outputId": "7d042d34-7a94-42ed-8cb1-9832fadd688a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!bzip2 -d lenta-ru-news.csv.bz2"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bzip2: Output file lenta-ru-news.csv already exists.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWZRDAhDimQk",
        "colab_type": "code",
        "outputId": "98c1534a-371b-42ae-bd5c-11f5b03bfad3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!ls\n",
        "!pip install pymorphy2[fast]\n",
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "185.zip\t\t\t   model.txt\n",
            "186.zip\t\t\t   news_mystem_skipgram_1000_20_2015.bin.gz\n",
            "data_paraphraser_norm.csv  news_mystem_skipgram_1000_20_2015.bin.gz.1\n",
            "lenta-ru-news.csv\t   paraphraser_gold.zip\n",
            "lenta-ru-news.csv.bz2\t   paraphrases_gold.xml\n",
            "meta.json\t\t   README\n",
            "model.bin\t\t   sample_data\n",
            "Requirement already satisfied: pymorphy2[fast] in /usr/local/lib/python3.6/dist-packages (0.8)\n",
            "Requirement already satisfied: pymorphy2-dicts<3.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (2.4.393442.3710985)\n",
            "Requirement already satisfied: dawg-python>=0.7 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.7.2)\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.6.2)\n",
            "Requirement already satisfied: DAWG>=0.7.3; extra == \"fast\" in /usr/local/lib/python3.6/dist-packages (from pymorphy2[fast]) (0.7.8)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zX7M6MAkoQ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import gensim\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "from collections import Counter,defaultdict\n",
        "from sklearn.decomposition import TruncatedSVD, NMF, PCA\n",
        "from string import punctuation\n",
        "import os\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from lxml import html\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "import gensim\n",
        "import numpy as np\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "morph = MorphAnalyzer()\n",
        "punct = punctuation+'«»—…“”*№–,'\n",
        "stops = set(stopwords.words('russian'))\n",
        "\n",
        "def normalize(text):\n",
        "    \n",
        "    words = [word.strip(punct) for word in text.lower().split()]\n",
        "    words = [morph.parse(word)[0].normal_form for word in words if word and word not in stops]\n",
        "\n",
        "    return ' '.join(words)\n",
        "\n",
        "def tokenize(text):\n",
        "    \n",
        "    words = [word.strip(punct) for word in text.lower().split()]\n",
        "\n",
        "    return ' '.join(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHRVBKC9niKF",
        "colab_type": "code",
        "outputId": "a5343bc2-509b-4c9b-c444-15ca2689eece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data_handler = open('lenta-ru-news.csv', 'r')\n",
        "data = data_handler.read()\n",
        "print(len(data))\n",
        "data = data[:6000000]"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1172327461\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qQ8d2jirWll",
        "colab_type": "code",
        "outputId": "f016dcb2-1487-404f-a19b-38c4bd4aeff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "source": [
        "print(data[:1000])\n"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "url,title,text,topic,tags,date\n",
            "https://lenta.ru/news/1914/09/16/hungarnn/,1914. Русские войска вступили в пределы Венгрии  ,\"Бои у Сопоцкина и Друскеник закончились отступлением германцев. Неприятель, приблизившись с севера к Осовцу начал артиллерийскую борьбу с крепостью. В артиллерийском бою принимают участие тяжелые калибры. С раннего утра 14 сентября огонь достиг значительного напряжения. Попытка германской пехоты пробиться ближе к крепости отражена. В Галиции мы заняли Дембицу. Большая колонна, отступавшая по шоссе от Перемышля к Саноку, обстреливалась с высот нашей батареей и бежала, бросив парки, обоз и автомобили. Вылазки гарнизона Перемышля остаются безуспешными. При продолжающемся отступлении австрийцев обнаруживается полное перемешивание их частей, захватываются новые партии пленных, орудия и прочая материальная часть. На перевале Ужок мы разбили неприятельский отряд, взяли его артиллерию и много пленных и, продолжая преследовать, вступили в пределы Венгрии. \n",
            "«Русский инвали\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWmUFssTRnoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_norm = [normalize(text) for text in data.split('.')]\n",
        "#data_norm = \".\".join(data_norm)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5J3zqnP8Rnmh",
        "colab_type": "code",
        "outputId": "7dc25b83-acc7-4032-bd97-62b756bb02fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "data_norm = [text for text in data_norm if text]\n",
        "print(len(data_norm))\n",
        "data_norm[:6]"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "45348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['url,title,text,topic,tags,date https://lenta',\n",
              " 'ru/news/1914/09/16/hungarnn/,1914',\n",
              " 'русский войско вступить предел венгрия бой сопоцкина друскеник закончиться отступление германец',\n",
              " 'неприятель приблизиться север осовца начать артиллерийский борьба крепость',\n",
              " 'артиллерийский бой принимать участие тяжёлый калибр',\n",
              " 'ранний утро 14 сентябрь огонь достигнуть значительный напряжение']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqanL3ybRnjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_w2v = gensim.models.Word2Vec([text.split() for text in data_norm], size=50, sg=1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xNTHoPBj4OD3",
        "colab_type": "code",
        "outputId": "39102003-48b4-47df-bbd7-ad4a9c66a669",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "my_w2v.most_similar('чечня')"
      ],
      "execution_count": 194,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('чеченский', 0.7967969179153442),\n",
              " ('дагестан', 0.7942893505096436),\n",
              " ('грозный', 0.7490787506103516),\n",
              " ('гудермес', 0.7484824657440186),\n",
              " ('аслан', 0.7417430281639099),\n",
              " ('масхадов', 0.7392385005950928),\n",
              " ('освобождение', 0.7381412386894226),\n",
              " ('республика', 0.736555814743042),\n",
              " ('контртеррористический', 0.7347901463508606),\n",
              " ('бандформирование', 0.7299843430519104)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UjOP9Mq4b54",
        "colab_type": "code",
        "outputId": "71c877f3-0945-4bc0-a403-6532dcb13fbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "dim = 50\n",
        "get_embedding(data_norm, my_w2v, dim)"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  if sys.path[0] == '':\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-3.49474225e-08, -7.41721237e-08,  1.11607458e-07, -3.82922143e-09,\n",
              "       -9.42828396e-09,  1.35756211e-08, -6.96944944e-08, -7.29867393e-08,\n",
              "       -3.47982368e-08,  4.86174913e-08,  3.44977032e-08, -6.52113968e-08,\n",
              "       -2.83295973e-08, -1.91513475e-08, -7.14392699e-08, -4.05819065e-08,\n",
              "       -1.74924073e-08, -7.77879924e-08,  6.25996716e-08, -2.39587802e-08,\n",
              "        1.30004079e-08,  3.37731848e-08,  3.05608136e-08, -1.20868121e-08,\n",
              "       -5.47487735e-08, -3.96093632e-08,  8.52064673e-09,  4.17529063e-08,\n",
              "       -1.58219761e-08,  2.11952309e-08, -1.16350043e-08,  4.90837604e-08,\n",
              "        5.71732886e-09,  4.07190688e-08, -3.54778285e-08,  7.26710787e-10,\n",
              "        3.11522482e-09, -3.95855632e-08, -4.60264265e-09, -4.13209868e-08,\n",
              "        5.08783302e-08, -4.64233319e-08, -6.20692625e-08, -1.76316925e-08,\n",
              "       -6.26251006e-08, -1.42117615e-08, -2.10682409e-08,  1.14434322e-08,\n",
              "       -4.25781555e-08,  2.47391519e-08])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WPvPEgeb98S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a491d7ff-6c8b-41b3-9ff7-b1faabcfbafa"
      },
      "source": [
        "!rm model.bin model.txt \n",
        "# !wget http://vectors.nlpl.eu/repository/20/186.zip\n",
        "# !wget http://vectors.nlpl.eu/repository/20/185.zip\n",
        "!unzip 185.zip\n",
        "!ls"
      ],
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  185.zip\n",
            "replace meta.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "  inflating: model.bin               \n",
            "  inflating: model.txt               \n",
            "replace README? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "185.zip\t\t\t   model.txt\n",
            "186.zip\t\t\t   news_mystem_skipgram_1000_20_2015.bin.gz\n",
            "data_paraphraser_norm.csv  news_mystem_skipgram_1000_20_2015.bin.gz.1\n",
            "lenta-ru-news.csv\t   paraphraser_gold.zip\n",
            "lenta-ru-news.csv.bz2\t   paraphrases_gold.xml\n",
            "meta.json\t\t   README\n",
            "model.bin\t\t   sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nepsHLlxfyW7",
        "colab_type": "code",
        "outputId": "7ec079dc-e0b3-41d0-8668-2591000d5d7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#rusv_v2w = gensim.models.KeyedVectors.load_word2vec_format('news_mystem_skipgram_1000_20_2015.bin.gz', binary=True)\n",
        "# rusv_v2w = gensim.models.KeyedVectors.load_word2vec_format('model.bin', binary=True)\n",
        "rusv_v2w = gensim.models.KeyedVectors.load_word2vec_format('model.bin', binary=True)\n"
      ],
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K80JkCtYfy0H",
        "colab_type": "code",
        "outputId": "e51efba1-2672-48fa-d6ce-8afc7c1a8ae9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "rusv_v2w.most_similar('путин_NOUN')"
      ],
      "execution_count": 281,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('путина_NOUN', 0.7462903261184692),\n",
              " ('россия_NOUN', 0.725328266620636),\n",
              " ('медведев_NOUN', 0.6876657605171204),\n",
              " ('зюган_NOUN', 0.6616120338439941),\n",
              " ('жириновский_ADJ', 0.6568332314491272),\n",
              " ('путин_PROPN', 0.6374367475509644),\n",
              " ('лдпр_NOUN', 0.6191665530204773),\n",
              " ('жирик_NOUN', 0.6120600700378418),\n",
              " ('кпрфа_PROPN', 0.6116076707839966),\n",
              " ('россие_NOUN', 0.6096259355545044)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 281
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-7ficwpVPDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_df_embedding(text, model, dim):\n",
        "    text = text.split()\n",
        "    words = Counter(text)\n",
        "    total = len(text)\n",
        "    vectors = np.zeros((len(words), dim))   \n",
        "    for i, word in enumerate(words):\n",
        "        #print(i)\n",
        "        try:\n",
        "            #print(model.most_similar(word))\n",
        "            v = model[word]\n",
        "        except (KeyError, ValueError) as errs:\n",
        "            #print(errs)\n",
        "            continue\n",
        "            #print(v*(words[word]/total))\n",
        "        vectors[i] = v*(words[word]/total)\n",
        "            #print(i)\n",
        "            #print(vectors[i])\n",
        "\n",
        "    #print(vectors)\n",
        "    if vectors.any():\n",
        "        #print(vector)\n",
        "        vector = np.average(vectors, axis=0)\n",
        "    else:\n",
        "        vector = np.zeros((dim))\n",
        "    \n",
        "    return vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwMRV4iJXrxw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_xml = html.fromstring(open('paraphrases_gold.xml', 'rb').read())\n",
        "texts_1 = []\n",
        "texts_2 = []\n",
        "classes = []\n",
        "\n",
        "for p in corpus_xml.xpath('//paraphrase'):\n",
        "    texts_1.append(p.xpath('./value[@name=\"text_1\"]/text()')[0])\n",
        "    texts_2.append(p.xpath('./value[@name=\"text_2\"]/text()')[0])\n",
        "    classes.append(p.xpath('./value[@name=\"class\"]/text()')[0])\n",
        "    \n",
        "df_data = pd.DataFrame({'text_1':texts_1, 'text_2':texts_2, 'label':classes})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xemqbs8R6R0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data['text_1_norm'] = df_data['text_1'].apply(normalize)\n",
        "df_data['text_2_norm'] = df_data['text_2'].apply(normalize)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foeHzuCyYbeN",
        "colab_type": "code",
        "outputId": "54d41f79-ae5c-4c52-f5af-fd267a4ef91b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "\n",
        "dim = 50\n",
        "df_data['text_1_notnorm'] = df_data['text_1'].apply(tokenize)\n",
        "df_data['text_2_notnorm'] = df_data['text_2'].apply(tokenize)\n",
        "\n",
        "X_text_1_ft = np.zeros((len(df_data['text_1_notnorm']), dim))\n",
        "X_text_2_ft = np.zeros((len(df_data['text_2_notnorm']), dim))\n",
        "\n",
        "for i, text in enumerate(df_data['text_1_notnorm'].values):\n",
        "    X_text_1_ft[i] = get_df_embedding(text, my_w2v, dim)\n",
        "    \n",
        "for i, text in enumerate(df_data['text_2_notnorm'].values):\n",
        "    X_text_2_ft[i] = get_df_embedding(text, my_w2v, dim)"
      ],
      "execution_count": 283,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rb8a07_TK9B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "b2ca1736-d1f9-47e2-b829-b622d5e933d6"
      },
      "source": [
        "df_data.head(5)"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_1</th>\n",
              "      <th>text_2</th>\n",
              "      <th>label</th>\n",
              "      <th>text_1_norm</th>\n",
              "      <th>text_2_norm</th>\n",
              "      <th>text_1_notnorm</th>\n",
              "      <th>text_2_notnorm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Цены на нефть восстанавливаются</td>\n",
              "      <td>Парламент Словакии поблагодарил народы бывшего...</td>\n",
              "      <td>-1</td>\n",
              "      <td>цена нефть восстанавливаться</td>\n",
              "      <td>парламент словакия поблагодарить народ бывший ...</td>\n",
              "      <td>цены на нефть восстанавливаются</td>\n",
              "      <td>парламент словакии поблагодарил народы бывшего...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\"Гоголь-центр\" покажет видеозапись скандальног...</td>\n",
              "      <td>Кехман запретил «Гоголь-центру» показывать вид...</td>\n",
              "      <td>-1</td>\n",
              "      <td>гоголь-центр показать видеозапись скандальный ...</td>\n",
              "      <td>кехман запретить гоголь-центр показывать видео...</td>\n",
              "      <td>гоголь-центр покажет видеозапись скандального ...</td>\n",
              "      <td>кехман запретил гоголь-центру показывать видео...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Агент: РФС вновь задерживает зарплату Фабио Ка...</td>\n",
              "      <td>СМИ: Агент Фабио Капелло грозится подать в суд...</td>\n",
              "      <td>-1</td>\n",
              "      <td>агент рфс вновь задерживать зарплата фабио кап...</td>\n",
              "      <td>сми агент фабио капелло грозиться подать суд рфс</td>\n",
              "      <td>агент рфс вновь задерживает зарплату фабио кап...</td>\n",
              "      <td>сми агент фабио капелло грозится подать в суд ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>День Победы в Москве обещает выдаться облачным</td>\n",
              "      <td>Любляна отпразднует День Победы вместе с Москвой</td>\n",
              "      <td>-1</td>\n",
              "      <td>день победа москва обещать выдаться облачный</td>\n",
              "      <td>люблян отпраздновать день победа вместе москва</td>\n",
              "      <td>день победы в москве обещает выдаться облачным</td>\n",
              "      <td>любляна отпразднует день победы вместе с москвой</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Посол РФ в США: Россия будет бороться с попытк...</td>\n",
              "      <td>Правительство запланировало заработать на лоте...</td>\n",
              "      <td>-1</td>\n",
              "      <td>посол рф сша россия бороться попытка переписат...</td>\n",
              "      <td>правительство запланировать заработать лотерея...</td>\n",
              "      <td>посол рф в сша россия будет бороться с попытка...</td>\n",
              "      <td>правительство запланировало заработать на лоте...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              text_1  ...                                     text_2_notnorm\n",
              "0                    Цены на нефть восстанавливаются  ...  парламент словакии поблагодарил народы бывшего...\n",
              "1  \"Гоголь-центр\" покажет видеозапись скандальног...  ...  кехман запретил гоголь-центру показывать видео...\n",
              "2  Агент: РФС вновь задерживает зарплату Фабио Ка...  ...  сми агент фабио капелло грозится подать в суд ...\n",
              "3     День Победы в Москве обещает выдаться облачным  ...   любляна отпразднует день победы вместе с москвой\n",
              "4  Посол РФ в США: Россия будет бороться с попытк...  ...  правительство запланировало заработать на лоте...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nf1GHgTxi4_D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_text_ft = np.concatenate([X_text_1_ft, X_text_2_ft], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ar1wE4jjJT6",
        "colab_type": "code",
        "outputId": "815881f7-2349-43f5-c87e-7b41024636e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "#Это получается предобученная модель\n",
        "y = df_data['label'].values\n",
        "train_X, valid_X, train_y, valid_y = train_test_split(X_text_ft, y,random_state=1)\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=7, min_samples_leaf=15,\n",
        "                             class_weight='balanced')\n",
        "clf.fit(train_X, train_y)\n",
        "preds = clf.predict(valid_X)\n",
        "print(classification_report(valid_y, preds))"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.48      0.49      0.48       181\n",
            "           0       0.51      0.52      0.52       207\n",
            "           1       0.26      0.24      0.25        93\n",
            "\n",
            "    accuracy                           0.45       481\n",
            "   macro avg       0.42      0.41      0.41       481\n",
            "weighted avg       0.45      0.45      0.45       481\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2zSaWSFv_TU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(clf, X_text_ft, y, cv=5, scoring = 'f1_macro')\n",
        "scores.mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DXr_4FbN2fDQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "88a87948-3832-4df5-bca2-753b354295a2"
      },
      "source": [
        "\n",
        "train_X, valid_X, train_y, valid_y = train_test_split(X_text_ft, y,random_state=1)\n",
        "clf = LogisticRegression(C=1000)\n",
        "clf.fit(train_X, train_y)\n",
        "preds = clf.predict(valid_X)\n",
        "print(classification_report(valid_y, preds))"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.47      0.57      0.51       181\n",
            "           0       0.49      0.57      0.52       207\n",
            "           1       0.29      0.06      0.11        93\n",
            "\n",
            "    accuracy                           0.47       481\n",
            "   macro avg       0.41      0.40      0.38       481\n",
            "weighted avg       0.44      0.47      0.44       481\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgqVsdwZr1Kf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e633dcc9-7052-4f02-b6b1-96d050930c1c"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(clf, X_text_ft, y, cv=5, scoring = 'f1_macro')\n",
        "scores.mean()"
      ],
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1863379372815407"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYi5woRlQRs9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "d4f20f43-9d73-44bb-b4e3-1b07df43c14d"
      },
      "source": [
        "corpus_csv"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text_1</th>\n",
              "      <th>text_2</th>\n",
              "      <th>text_1_norm</th>\n",
              "      <th>text_2_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Полицейским разрешат стрелять на поражение по ...</td>\n",
              "      <td>Полиции могут разрешить стрелять по хулиганам ...</td>\n",
              "      <td>полицейский_NOUN разрешать_VERB стрелять_VERB ...</td>\n",
              "      <td>полиция_NOUN мочь_VERB разрешать_VERB стрелять...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Право полицейских на проникновение в жилище ре...</td>\n",
              "      <td>Правила внесудебного проникновения полицейских...</td>\n",
              "      <td>право_ADV полицейский_NOUN на_ADP проникновени...</td>\n",
              "      <td>правило_NOUN внесудебный_ADJ проникновение_NOU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Президент Египта ввел чрезвычайное положение в...</td>\n",
              "      <td>Власти Египта угрожают ввести в стране чрезвыч...</td>\n",
              "      <td>президент_NOUN египет_NOUN вводить_VERB чрезвы...</td>\n",
              "      <td>власть_NOUN египет_NOUN угрожать_VERB вводить_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1</td>\n",
              "      <td>Вернувшихся из Сирии россиян волнует вопрос тр...</td>\n",
              "      <td>Самолеты МЧС вывезут россиян из разрушенной Си...</td>\n",
              "      <td>вернуться_VERB из_ADP сирия_NOUN россиянин_NOU...</td>\n",
              "      <td>самолет_NOUN мчс_NOUN вывозить_VERB россиянин_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>В Москву из Сирии вернулись 2 самолета МЧС с р...</td>\n",
              "      <td>Самолеты МЧС вывезут россиян из разрушенной Си...</td>\n",
              "      <td>в_ADP москва_NOUN из_ADP сирия_NOUN вернуться_...</td>\n",
              "      <td>самолет_NOUN мчс_NOUN вывозить_VERB россиянин_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7222</th>\n",
              "      <td>0</td>\n",
              "      <td>Путин освободил от должности ряд генералов</td>\n",
              "      <td>Путин снял с должностей более 20 руководителей...</td>\n",
              "      <td>путин_NOUN освобождать_VERB от_ADP должность_N...</td>\n",
              "      <td>путин_NOUN снимать_VERB с_ADP должность_NOUN м...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7223</th>\n",
              "      <td>-1</td>\n",
              "      <td>Облака над Москвой в День Победы разгонят девя...</td>\n",
              "      <td>Путеводитель по Дню Победы: как провести 9 мая...</td>\n",
              "      <td>облако_NOUN над_ADP москва_NOUN в_ADP день_NOU...</td>\n",
              "      <td>путеводитель_NOUN по_ADP день_NOUN победа_NOUN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7224</th>\n",
              "      <td>-1</td>\n",
              "      <td>Любляна отпразднует День Победы вместе с Москвой</td>\n",
              "      <td>В Москве ограничат движение в связи с Днем Победы</td>\n",
              "      <td>любляна_NOUN отпраздновать_VERB день_NOUN побе...</td>\n",
              "      <td>в_ADP москва_NOUN ограничивать_VERB движение_N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7225</th>\n",
              "      <td>-1</td>\n",
              "      <td>Девять самолетов ВВС разгонят облака над Москв...</td>\n",
              "      <td>В Москве ограничат движение в связи с Днем Победы</td>\n",
              "      <td>девять_NUM самолет_NOUN ввс_NOUN разгонять_VER...</td>\n",
              "      <td>в_ADP москва_NOUN ограничивать_VERB движение_N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7226</th>\n",
              "      <td>-1</td>\n",
              "      <td>9 мая метрополитен Петербурга будет работать к...</td>\n",
              "      <td>Мартынов: комендантский час в Донецке 9 мая бу...</td>\n",
              "      <td>май_NOUN метрополитен_NOUN петербург_NOUN быть...</td>\n",
              "      <td>мартынов_NOUN комендантский_ADJ час_NOUN в_ADP...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7227 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      label  ...                                        text_2_norm\n",
              "0         0  ...  полиция_NOUN мочь_VERB разрешать_VERB стрелять...\n",
              "1         0  ...  правило_NOUN внесудебный_ADJ проникновение_NOU...\n",
              "2         0  ...  власть_NOUN египет_NOUN угрожать_VERB вводить_...\n",
              "3        -1  ...  самолет_NOUN мчс_NOUN вывозить_VERB россиянин_...\n",
              "4         0  ...  самолет_NOUN мчс_NOUN вывозить_VERB россиянин_...\n",
              "...     ...  ...                                                ...\n",
              "7222      0  ...  путин_NOUN снимать_VERB с_ADP должность_NOUN м...\n",
              "7223     -1  ...  путеводитель_NOUN по_ADP день_NOUN победа_NOUN...\n",
              "7224     -1  ...  в_ADP москва_NOUN ограничивать_VERB движение_N...\n",
              "7225     -1  ...  в_ADP москва_NOUN ограничивать_VERB движение_N...\n",
              "7226     -1  ...  мартынов_NOUN комендантский_ADJ час_NOUN в_ADP...\n",
              "\n",
              "[7227 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1SnTUYfNlcg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus_csv = pd.read_csv('data_paraphraser_norm.csv', error_bad_lines=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my1_c2cNtWDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_distances\n",
        "dim = 50\n",
        "\n",
        "# corpus_csv['text_1_norm'] = corpus_csv['text_1_norm'].apply()\n",
        "# corpus_csv['text_2_norm'] = corpus_csv['text_2_norm'].apply()\n",
        "\n",
        "X_text_1_ft = np.zeros((len(corpus_csv['text_1_norm']), 300))\n",
        "X_text_2_ft = np.zeros((len(corpus_csv['text_2_norm']), 300))\n",
        "\n",
        "for i, text in enumerate(corpus_csv['text_1_norm'].values):\n",
        "    X_text_1_ft[i] = get_df_embedding(text, rusv_v2w, 300)\n",
        "    \n",
        "for i, text in enumerate(corpus_csv['text_2_norm'].values):\n",
        "    X_text_2_ft[i] = get_df_embedding(text, rusv_v2w, 300)\n",
        "    #print(X_text_2_ft[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL4XpW1UNIsB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "b0ceaf70-dbcb-4e49-da0c-ce6c51861130"
      },
      "source": [
        "X_text_ft = np.concatenate([X_text_1_ft, X_text_2_ft], axis=1)\n",
        "X_text_ft"
      ],
      "execution_count": 299,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.00795916, -0.01174852, -0.01734468, ...,  0.00814719,\n",
              "         0.01839041, -0.01368497],\n",
              "       [-0.00072169,  0.00059484, -0.01141266, ...,  0.0163677 ,\n",
              "         0.02709406, -0.02394614],\n",
              "       [-0.01263203,  0.00081496,  0.00657211, ...,  0.01804899,\n",
              "         0.02425772, -0.01231225],\n",
              "       ...,\n",
              "       [-0.00961985, -0.02270706, -0.00570588, ...,  0.00414114,\n",
              "         0.01269401, -0.0114705 ],\n",
              "       [-0.00658599, -0.00920898,  0.00010471, ...,  0.00414114,\n",
              "         0.01269401, -0.0114705 ],\n",
              "       [-0.01109063, -0.01903416, -0.01624854, ...,  0.00117148,\n",
              "         0.01932425,  0.00015063]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 299
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPQvZdG0NIuY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "70e3cbac-99d6-44aa-f310-818a0998804e"
      },
      "source": [
        "y = corpus_csv['label'].values\n",
        "train_X, valid_X, train_y, valid_y = train_test_split(X_text_ft, y,random_state=1)\n",
        "clf = RandomForestClassifier(n_estimators=100, max_depth=7, min_samples_leaf=15,\n",
        "                             class_weight='balanced')\n",
        "clf.fit(train_X, train_y)\n",
        "preds = clf.predict(valid_X)\n",
        "print(classification_report(valid_y, preds))"
      ],
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.53      0.59      0.56       629\n",
            "           0       0.49      0.50      0.49       737\n",
            "           1       0.38      0.30      0.34       441\n",
            "\n",
            "    accuracy                           0.48      1807\n",
            "   macro avg       0.47      0.46      0.46      1807\n",
            "weighted avg       0.48      0.48      0.48      1807\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s52-nFsouZSY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a08f78a2-9b63-4c33-c865-8ea8aa124d0a"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(clf, X_text_ft, y, cv=5, scoring = 'f1_micro')\n",
        "scores.mean()"
      ],
      "execution_count": 305,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4292117139753143"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wd1sn0sFiU2S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "15857e9c-2ded-4d72-9e74-143caa80908c"
      },
      "source": [
        "y = corpus_csv['label'].values\n",
        "train_X, valid_X, train_y, valid_y = train_test_split(X_text_ft, y,random_state=1)\n",
        "clf = RandomForestClassifier(n_estimators=200, max_depth=7, min_samples_leaf=15,\n",
        "                             class_weight='balanced')\n",
        "clf.fit(train_X, train_y)\n",
        "preds = clf.predict(valid_X)\n",
        "print(classification_report(valid_y, preds))"
      ],
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.54      0.58      0.56       629\n",
            "           0       0.49      0.51      0.50       737\n",
            "           1       0.39      0.32      0.35       441\n",
            "\n",
            "    accuracy                           0.49      1807\n",
            "   macro avg       0.47      0.47      0.47      1807\n",
            "weighted avg       0.48      0.49      0.48      1807\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxNJd005SPmX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f6c9114-4ab5-4191-f93b-4e96919f66a6"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "scores = cross_val_score(clf, X_text_ft, y, cv=5, scoring = 'f1_micro')\n",
        "scores.mean()"
      ],
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.43959492120011295"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAVJAdyeSPo-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEioWjNzSPrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiDrMo38SPuN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LeLu52_BSPwl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuVWrnotHDaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_lines_norm = [normalize(text) for text in data.splitlines()]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUvjc4p2HDdF",
        "colab_type": "code",
        "outputId": "1fa0714e-072e-4658-ebae-b51141017044",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "print(len(data_lines_norm))\n",
        "data_lines_norm[:4]"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4251\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['url,title,text,topic,tags,date',\n",
              " 'https://lenta.ru/news/1914/09/16/hungarnn/,1914 русский войско вступить предел венгрия бой сопоцкина друскеник закончиться отступление германец неприятель приблизиться север осовца начать артиллерийский борьба крепость артиллерийский бой принимать участие тяжёлый калибр ранний утро 14 сентябрь огонь достигнуть значительный напряжение попытка германский пехота пробиться близкий крепость отразить галиция занять дембица большой колонна отступать шоссе перемышль санок обстреливаться высота наш батарея бежать бросить парка обоз автомобиль вылазка гарнизон перемышль оставаться безуспешный продолжаться отступление австриец обнаруживаться полный перемешивание часть захватываться новое партия пленный орудие прочий материальный часть перевал ужок разбить неприятельский отряд взять артиллерия пленный продолжать преследовать вступить предел венгрия',\n",
              " 'русский инвалид 16 сентябрь 1914 года.\",библиотека,первать мировая,1914/09/16',\n",
              " 'https://lenta.ru/news/1914/09/16/lermontov/,1914 празднование столетие м.ю лермонтов отложить министерство народный просвещение вид происходить чрезвычайный событие признать соответственный день годовщина день рождение м.ю лермонтов 2-го октябрь 1914 год ограничиться совершение учебный заведение панихида поэт отложить празднование юбилей благоприятный время']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giKPmA2rHDfp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cv = CountVectorizer(min_df=3, max_df=0.4, max_features=1000)\n",
        "X = cv.fit_transform(data_lines_norm)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw1gN-gan_HV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "0d5a367f-9c8b-4df2-f747-1b5c2b0228fd"
      },
      "source": [
        "nmf = NMF(50)\n",
        "nmf.fit(X)"
      ],
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NMF(alpha=0.0, beta_loss='frobenius', init=None, l1_ratio=0.0, max_iter=200,\n",
              "    n_components=50, random_state=None, shuffle=False, solver='cd', tol=0.0001,\n",
              "    verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVitMIL-obdG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fa66a045-51db-4145-f74b-58c76f9d93c3"
      },
      "source": [
        "svd = TruncatedSVD(50)\n",
        "svd.fit(X)"
      ],
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TruncatedSVD(algorithm='randomized', n_components=50, n_iter=5,\n",
              "             random_state=None, tol=0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHqd1GjopIhD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fast_text = gensim.models.FastText([text.split() for text in data_lines_norm], size=50, \n",
        "                                   min_n=4, max_n=8) \n",
        "w2v = gensim.models.Word2Vec([text.split() for text in data_lines_norm], size=50, sg=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Twk5qgdPpInF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QpbaMaNodEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2word = {i:w for i,w in enumerate(cv.get_feature_names())}\n",
        "word2id = {w:i for i,w in id2word.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFo-zTqaotLn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2vec_svd = nmf.components_.T\n",
        "id2vec_nmf = svd.components_.T\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUXwlLYNow3X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def most_similar(word, id2vec):\n",
        "    similar = [id2word[i] for i in cosine_distances(id2vec[word2id[word]].reshape(1, -1), id2vec).argsort()[0][:10]]\n",
        "    return similar"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bgjk06F_rWUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_distance(model, text1, text2, dim=dim):\n",
        "  dist_dict = []\n",
        "  X_text_1_ft = np.zeros((len(data['text_1_notnorm']), dim))\n",
        "  X_text_2_ft = np.zeros((len(data['text_2_notnorm']), dim))\n",
        "\n",
        "  for i, text in enumerate(data['text_1_notnorm'].values):\n",
        "      X_text_1_ft[i] = get_df_embedding(text, fast_text, dim)\n",
        "      \n",
        "  for i, text in enumerate(data['text_2_notnorm'].values):\n",
        "      X_text_2_ft[i] = get_df_embedding(text, fast_text, dim)\n",
        "  distance = cosine_distance(X[i], X[i])\n",
        "  dist_dict.append(distance)\n",
        "  return dist_dict\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuM2A85CuRPW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "d3ba426a-90e0-4e27-c273-94245451d6af"
      },
      "source": [
        "vectors_df = corpus_csv\n",
        "vectors_df"
      ],
      "execution_count": 311,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text_1</th>\n",
              "      <th>text_2</th>\n",
              "      <th>text_1_norm</th>\n",
              "      <th>text_2_norm</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Полицейским разрешат стрелять на поражение по ...</td>\n",
              "      <td>Полиции могут разрешить стрелять по хулиганам ...</td>\n",
              "      <td>полицейский_NOUN разрешать_VERB стрелять_VERB ...</td>\n",
              "      <td>полиция_NOUN мочь_VERB разрешать_VERB стрелять...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Право полицейских на проникновение в жилище ре...</td>\n",
              "      <td>Правила внесудебного проникновения полицейских...</td>\n",
              "      <td>право_ADV полицейский_NOUN на_ADP проникновени...</td>\n",
              "      <td>правило_NOUN внесудебный_ADJ проникновение_NOU...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Президент Египта ввел чрезвычайное положение в...</td>\n",
              "      <td>Власти Египта угрожают ввести в стране чрезвыч...</td>\n",
              "      <td>президент_NOUN египет_NOUN вводить_VERB чрезвы...</td>\n",
              "      <td>власть_NOUN египет_NOUN угрожать_VERB вводить_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-1</td>\n",
              "      <td>Вернувшихся из Сирии россиян волнует вопрос тр...</td>\n",
              "      <td>Самолеты МЧС вывезут россиян из разрушенной Си...</td>\n",
              "      <td>вернуться_VERB из_ADP сирия_NOUN россиянин_NOU...</td>\n",
              "      <td>самолет_NOUN мчс_NOUN вывозить_VERB россиянин_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>В Москву из Сирии вернулись 2 самолета МЧС с р...</td>\n",
              "      <td>Самолеты МЧС вывезут россиян из разрушенной Си...</td>\n",
              "      <td>в_ADP москва_NOUN из_ADP сирия_NOUN вернуться_...</td>\n",
              "      <td>самолет_NOUN мчс_NOUN вывозить_VERB россиянин_...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7222</th>\n",
              "      <td>0</td>\n",
              "      <td>Путин освободил от должности ряд генералов</td>\n",
              "      <td>Путин снял с должностей более 20 руководителей...</td>\n",
              "      <td>путин_NOUN освобождать_VERB от_ADP должность_N...</td>\n",
              "      <td>путин_NOUN снимать_VERB с_ADP должность_NOUN м...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7223</th>\n",
              "      <td>-1</td>\n",
              "      <td>Облака над Москвой в День Победы разгонят девя...</td>\n",
              "      <td>Путеводитель по Дню Победы: как провести 9 мая...</td>\n",
              "      <td>облако_NOUN над_ADP москва_NOUN в_ADP день_NOU...</td>\n",
              "      <td>путеводитель_NOUN по_ADP день_NOUN победа_NOUN...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7224</th>\n",
              "      <td>-1</td>\n",
              "      <td>Любляна отпразднует День Победы вместе с Москвой</td>\n",
              "      <td>В Москве ограничат движение в связи с Днем Победы</td>\n",
              "      <td>любляна_NOUN отпраздновать_VERB день_NOUN побе...</td>\n",
              "      <td>в_ADP москва_NOUN ограничивать_VERB движение_N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7225</th>\n",
              "      <td>-1</td>\n",
              "      <td>Девять самолетов ВВС разгонят облака над Москв...</td>\n",
              "      <td>В Москве ограничат движение в связи с Днем Победы</td>\n",
              "      <td>девять_NUM самолет_NOUN ввс_NOUN разгонять_VER...</td>\n",
              "      <td>в_ADP москва_NOUN ограничивать_VERB движение_N...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7226</th>\n",
              "      <td>-1</td>\n",
              "      <td>9 мая метрополитен Петербурга будет работать к...</td>\n",
              "      <td>Мартынов: комендантский час в Донецке 9 мая бу...</td>\n",
              "      <td>май_NOUN метрополитен_NOUN петербург_NOUN быть...</td>\n",
              "      <td>мартынов_NOUN комендантский_ADJ час_NOUN в_ADP...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7227 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      label  ...                                        text_2_norm\n",
              "0         0  ...  полиция_NOUN мочь_VERB разрешать_VERB стрелять...\n",
              "1         0  ...  правило_NOUN внесудебный_ADJ проникновение_NOU...\n",
              "2         0  ...  власть_NOUN египет_NOUN угрожать_VERB вводить_...\n",
              "3        -1  ...  самолет_NOUN мчс_NOUN вывозить_VERB россиянин_...\n",
              "4         0  ...  самолет_NOUN мчс_NOUN вывозить_VERB россиянин_...\n",
              "...     ...  ...                                                ...\n",
              "7222      0  ...  путин_NOUN снимать_VERB с_ADP должность_NOUN м...\n",
              "7223     -1  ...  путеводитель_NOUN по_ADP день_NOUN победа_NOUN...\n",
              "7224     -1  ...  в_ADP москва_NOUN ограничивать_VERB движение_N...\n",
              "7225     -1  ...  в_ADP москва_NOUN ограничивать_VERB движение_N...\n",
              "7226     -1  ...  мартынов_NOUN комендантский_ADJ час_NOUN в_ADP...\n",
              "\n",
              "[7227 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 311
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20L4yo5ExNgZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dim = 50\n",
        "cosine_dist = []\n",
        "vectors_df['text_1_notnorm'] = vectors_df['text_1'].apply(tokenize)\n",
        "vectors_df['text_2_notnorm'] = vectors_df['text_2'].apply(tokenize)\n",
        "\n",
        "X_text_1_ft = np.zeros((len(vectors_df['text_1_norm']), 300))\n",
        "X_text_2_ft = np.zeros((len(vectors_df['text_2_norm']), 300))\n",
        "\n",
        "for i, text in enumerate(vectors_df['text_1_norm'].values):\n",
        "    X_text_1_ft[i] = get_df_embedding(text, rusv_v2w, 300)\n",
        "    \n",
        "for i, text in enumerate(vectors_df['text_2_norm'].values):\n",
        "    X_text_2_ft[i] = get_df_embedding(text, rusv_v2w, 300)\n",
        "    #print(X_text_2_ft[i])\n",
        "cosine_distances()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5gFg4XG0BES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_text_ft = np.concatenate([X_text_1_ft, X_text_2_ft], axis=1)\n",
        "X_text_ft\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}